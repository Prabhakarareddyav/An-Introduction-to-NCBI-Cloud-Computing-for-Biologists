<!doctype html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">

<!-- Begin Jekyll SEO tag v2.7.1 -->
<title>Objective 0 - Logging in &amp; Navigating the AWS Console Page | Introduction to NCBI Cloud Computing</title>
<meta name="generator" content="Jekyll v3.9.0" />
<meta property="og:title" content="Objective 0 - Logging in &amp; Navigating the AWS Console Page" />
<meta property="og:locale" content="en_US" />
<link rel="canonical" href="http://localhost:4000/" />
<meta property="og:url" content="http://localhost:4000/" />
<meta property="og:site_name" content="Introduction to NCBI Cloud Computing" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Objective 0 - Logging in &amp; Navigating the AWS Console Page" />
<script type="application/ld+json">
{"@type":"WebSite","headline":"Objective 0 - Logging in &amp; Navigating the AWS Console Page","url":"http://localhost:4000/","name":"Introduction to NCBI Cloud Computing","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->

    <link rel="stylesheet" href="/assets/css/style.css?v=609d4b7d766acc2bd73a93a7b5b25f792a88ae86">
    <script src="https://code.jquery.com/jquery-3.3.0.min.js" integrity="sha256-RTQy8VOmNlT6b2PIRur37p6JEBZUE7o8wPgMvu18MC4=" crossorigin="anonymous"></script>
    <script src="/assets/js/main.js"></script>
    
    <!--[if lt IE 9]>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv.min.js" integrity="sha256-3Jy/GbSLrg0o9y5Z5n1uw0qxZECH7C6OQpVBgNFYa0g=" crossorigin="anonymous"></script>
    <![endif]-->
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">

  </head>
  <body>
    
      <header>
        <h1>Introduction to NCBI Cloud Computing</h1>
	<span id='logo'></span>
	<img src='doc_images/NCBI_white_fit.png', alt='NCBI', width='300px'>
      </header>

      <div id="banner">
        <a href="https://github.com/parkcoj/Intro-to-NCBI-Cloud-Computing" class="button fork">View On GitHub</a>
        <a href="https://parkcoj.github.io/Intro-to-NCBI-Cloud-Computing/slides.pdf" class="button slides" target="_blank">Download Slides</a>
        
      </div><!-- end banner -->

    <div class="wrapper">
      <nav>
        <ul></ul>
      </nav>
      <section>
        <h1 id="objective-0---logging-in--navigating-the-aws-console-page">Objective 0 - Logging in &amp; Navigating the AWS Console Page</h1>

<p>1) Find your credential email with subject: <strong>NCBI Codethon Credentials</strong></p>

<p><img src="/doc_images/img1.jpg" alt="img1" width="60%" /></p>

<p>2) Navigate to <a href="https://codeathon.ncbi.nlm.nih.gov">https://codeathon.ncbi.nlm.nih.gov</a> and login using the credentials from the email <em>(left image)</em> and create a new password after logging in <em>(right image)</em></p>

<p><img src="/doc_images/img2.jpg" alt="img2" width="60%" /></p>

<p>3) Click <strong>Sign-In</strong> under the AWS Console Sign-In column on the new page</p>

<p><img src="/doc_images/img3.jpg" alt="img3" /></p>

<p>4) If you see <strong>AWS Management Console</strong> like the screenshot below, you have successfully logged in to the AWS Console!</p>

<p><img src="/doc_images/img4.jpg" alt="img4" width="60%" /></p>

<blockquote>
  <p><strong>NOTE:</strong> If you are logged out or get kicked out of the console, simply return to <a href="https://codeathon.ncbi.nlm.nih.gov">https://codeathon.ncbi.nlm.nih.gov</a> and log in again (remember your newly created password!) to get back to the console home page.</p>
</blockquote>

<blockquote>
  <p><strong>NOTE:</strong> This login method is unique to the workshop. If you want to create your own account after the workshop, visit the link below and follow the steps:
<a href="https://aws.amazon.com/premiumsupport/knowledge-center/create-and-activate-aws-account/">https://aws.amazon.com/premiumsupport/knowledge-center/create-and-activate-aws-account/</a></p>
</blockquote>

<h1 id="objective-1---search-for-the-sequence-reads-deposited-into-ncbis-sra-database-using-aws-athena">Objective 1 - Search for the sequence reads deposited into NCBI’s SRA database using AWS Athena</h1>

<h2 id="creating-an-s3-bucket">Creating an S3 Bucket</h2>

<p>Before we can use Athena, we need to make an S3 bucket that we can save our results to as we search the SRA metadata tables. So, let’s go make one!</p>

<p>1) Use the search bar at the top of the console page to search for <strong>S3</strong> and click on the first result</p>

<p><img src="/doc_images/img5.jpg" alt="img5" width="60%" /></p>

<p>2) Click the orange <strong>Create Bucket</strong> button on the right-hand side of the screen</p>

<p><img src="/doc_images/img6.jpg" alt="img6" width="60%" /></p>

<p>3) Enter a bucket name and make sure the region is set to <code class="language-plaintext highlighter-rouge">US East (N. Virginia) us-east-1</code></p>

<p><strong>S3 bucket names must be completely unique.</strong></p>

<p>For this workshop, use the format <code class="language-plaintext highlighter-rouge">&lt;username&gt;-cloud-workshop</code> where <code class="language-plaintext highlighter-rouge">&lt;username&gt;</code> is the username you used to login</p>

<p><img src="/doc_images/img7.jpg" alt="img7" width="60%" /></p>

<p>4) Scroll down to the <strong>Block Public Access settings for this bucket</strong> section. Deselect the blue checkbox at the top and select the bottom 2 checkboxes. Then check the box underneath the warning symbol to acknowledge your changes to the public access settings</p>

<blockquote>
  <p><strong>NOTE:</strong> We turn on Public Access so that we can upload our files from the bucket directly to public websites like NCBI (<em>e.g.</em>, we will be uploading result files from our bucket to the Genome Data Viewer later today). By default, you should keep your bucket from Public Access unless you explicitly need it</p>
</blockquote>

<p><img src="/doc_images/img8.jpg" alt="img8" width="60%" /></p>

<p>5) Ignore the rest of the settings and scroll to the bottom of the page. Click the orange <strong>Create Bucket</strong> button.</p>

<p><img src="/doc_images/img9.jpg" alt="img9" width="80%" /></p>

<p>6) Clicking the button will redirect you back to the main S3 page. You should be able to find your new bucket in the list. If so, you have successfully created an S3 bucket!</p>

<p><img src="/doc_images/img10.jpg" alt="img10" width="80%" /></p>

<p>Now that we have an S3 bucket ready, we can go see what the Athena page looks like!</p>

<h2 id="navigating-to-athena">Navigating to Athena</h2>

<p>1) Use the search bar at the top of the console page to search for <strong>Athena</strong> and click on the first result</p>

<p><img src="/doc_images/img11.jpg" alt="img11" width="60%" /></p>

<p> </p>

<p>2) Visiting the Athena page should prompt you with one notification about the “new Athena console experience”. You can just click the “X” to remove it.</p>

<p> </p>

<p><img src="/doc_images/img12.jpg" alt="img12" /></p>

<p>3) To make sure Athena saves our search results in the correct S3 bucket, we need to tell it which one to use. Good thing we just made one, eh?  Click <strong>Settings</strong> in the top left of the screen</p>

<p><img src="/doc_images/img13.jpg" alt="img13" width="60%" /></p>

<p>4) Click the <strong>Manage</strong> button on the right <em>(1st image)</em> then <strong>Browse S3</strong> on the next page <em>(2nd image)</em> to see the list of S3 buckets in our account. Scroll to find your S3 bucket then click the radio button to the left of the name and click <strong>Choose</strong> in the bottom right <em>(3rd image)</em>. Finally, click <strong>Save</strong> <em>(4th image)</em>.</p>

<p><img src="/doc_images/img14.jpg" alt="img14" width="60%" /></p>

<p><img src="/doc_images/img15.jpg" alt="img15" width="60%" /></p>

<p><img src="/doc_images/img16.jpg" alt="img16" width="60%" /></p>

<p><img src="/doc_images/img16_1.jpg" alt="img16_1" /></p>

<p>Now that we can save Athena results we can run some searches! The very last step to doing that is to import the table we want to search into Athena using another AWS service - Glue. However, to save time, this has already been done prior to the workshop by the instructor.</p>

<blockquote>
  <p>For the detailed instructions on using AWS Glue to add a table to Athena, visit the Supplementary Text: <strong>Instructions for AWS Glue</strong>!</p>
</blockquote>

<h2 id="exploring-athena-tables">Exploring Athena Tables</h2>

<p>These steps aren’t necessary to do before every Athena query, but they are useful when exploring a new table.</p>

<p>1) Navigate back to the <strong>Editor</strong> tab and click the dropdown menu underneath the <strong>Database</strong> section and click <strong>sra</strong> to set it as the active database. If you do not see this as an option, refresh the page and check again.</p>

<p><img src="/doc_images/img17.jpg" alt="img17" width="80%" /></p>

<p>2) Look at the <strong>Tables</strong> section and click the ellipses next to the <strong>metadata</strong> table, then click <strong>Preview Table</strong> to automatically run a sample command which will give you 10 random lines from the table</p>

<p><img src="/doc_images/img18.jpg" alt="img18" width="80%" /></p>

<blockquote>
  <p>You can also click the <strong>+</strong> button next to the Metadata name to see a list of all the columns in the table.</p>
</blockquote>

<blockquote>
  <p>For SRA based tables, you can also visit the following link to get the definition of each column in the table: <a href="https://www.ncbi.nlm.nih.gov/sra/docs/sra-cloud-based-examples/">https://www.ncbi.nlm.nih.gov/sra/docs/sra-cloud-based-examples/</a></p>
</blockquote>

<h2 id="querying-our-dataset">Querying Our Dataset</h2>

<p>1) The following link is the actual publication for our case study today. Scroll to the very bottom and find the <strong>Data Availability</strong> section: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5778042/">https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5778042/</a></p>

<p><img src="/doc_images/img19.jpg" alt="img19" /></p>

<blockquote>
  <p>You can also use the SRA Run Selector on the NCBI website to download data from NCBI directly to your S3 bucket! Find more information and a tutorial here:<br />
<a href="https://www.ncbi.nlm.nih.gov/sra/docs/data-delivery/">https://www.ncbi.nlm.nih.gov/sra/docs/data-delivery/</a></p>
</blockquote>

<p>2) The paper stored the data we need under and ID <strong>SRP125431</strong>, but we don’t know exactly which column that is associated with. So, scroll through the preview table we made earlier to find a column filled with similar values.</p>

<p><img src="/doc_images/img20.jpg" alt="img20" width="60%" /></p>

<blockquote>
  <p>The <strong>Preview Table</strong> query we used to make this example pulls random lines from the table, so the values within your table may look different from this screenshot. The important info for us is that each value in this <strong>sra_study</strong> column starts with <strong>“SRP” (or “ERP”)</strong></p>
</blockquote>

<p>3) Now that we know which column to query for our data (sra_study), we can build the Athena query. Look to the panel where we enter our Athena queries. Click <strong>New Query 1</strong> to navigate back to the empty panel so we can write our own query.</p>

<p><img src="/doc_images/img21.jpg" alt="img21" width="60%" /></p>

<blockquote>
  <p>Fun fact: If you navigate back to <strong>Query 1</strong> you should still see the result table for that query! Athena will save that view for you until you run a new query in that tab or close the webpage.</p>
</blockquote>

<p>4) Copy/paste the following command into the query box in Athena <em>(circled in yellow)</em>, then click the blue <strong>Run Query</strong> button <em>(circled in red)</em>.</p>

<div class="code-header">
    <button class="copy-code-button" aria-label="Copy code to clipboard"></button>
</div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>SELECT *
FROM "sra"."metadata"
WHERE sra_study = 'SRP125431'
</code></pre></div></div>

<p><img src="/doc_images/img22.jpg" alt="img22" width="60%" /></p>

<p>5) If you see a results table with three rows like the partial screenshot below, you have successfully found your data!</p>

<p><img src="/doc_images/img23.jpg" alt="img23" width="80%" /></p>

<p>6) Click the <strong>Download results</strong> button on the top-right corner of the results panel to download your file to your computer in CSV format. You should be able to open this in Microsoft Excel, Google Sheets, or a regular text editor (e.g., Notepad for PC, TextEdit for Mac). We will review this file later, so keep it handy.</p>

<p><img src="/doc_images/img24.jpg" alt="img24" width="60%" /></p>

<blockquote>
  <p>Want to challenge yourself? Visit the supplementary text (section: <strong>SQL challenges</strong>) to find some questions you can build your own SQL query for. Plus, find more advanced SQL query techniques and a deeper breakdown of the SRA metadata table too!</p>
</blockquote>

<h1 id="objective-2---aligning-sequence-reads-using-aws-ec2--magicblast">Objective 2 - Aligning Sequence Reads using AWS EC2 &amp; MagicBLAST</h1>

<h2 id="launching-an-ec2-instance">Launching an EC2 Instance</h2>

<p>1) Use the search ar at the top of the console page to search for <strong>EC2</strong> and click on the first result</p>

<p><img src="/doc_images/img25.jpg" alt="img25" width="60%" /></p>

<p>2) Scroll down a little and click the orange Launch Instance button and Launch Instance from its drop-down menu</p>

<p><img src="/doc_images/img26.jpg" alt="img26" width="60%" /></p>

<p>3) On the <strong>Step 1: Choose an Amazon Machine Image (AMI)</strong> page - type <strong>Ubuntu</strong> into the search bar and hit enter <em>(top image)</em> then click the blue <strong>Select</strong> on the right hand-side of the <strong>Ubuntu Server 20.04</strong> image option <em>(bottom image)</em>.</p>

<p><img src="/doc_images/img27.jpg" alt="img27" width="60%" /></p>

<p><img src="/doc_images/img28.jpg" alt="img28" width="60%" /></p>

<p>4) On the <strong>Step 2: Choose an Instance Type</strong> page - use the filter menus near the top of the menu to set the Instance Family to <strong>m4</strong></p>

<p><img src="/doc_images/img29.jpg" alt="img29" width="60%" /></p>

<p>5) Look to the table below the filter buttons and check the box in the 2nd row from the top where the type is <strong>m4.large</strong></p>

<p><img src="/doc_images/img30.jpg" alt="img30" width="60%" /></p>

<p>6) Click <strong>Next: Configure Instance Details</strong></p>

<p><img src="/doc_images/img31.jpg" alt="img31" width="80%" /></p>

<p>7) On page <strong>Step 3: Configure Instance Details</strong> - set the IAM role to <strong>NCBI-Workshop-participant-EC2-instance</strong> <em>(top image)</em>. Leave all other settings alone and click <strong>Next: Add Storage</strong> in the bottom right <em>(bottom image)</em></p>

<p><img src="/doc_images/img32.jpg" alt="img32" width="60%" /></p>

<p><img src="/doc_images/img33.jpg" alt="img33" width="80%" /></p>

<p>8) On page <strong>Step 4: Add Storage</strong> - Change the Size (GiB) to <strong>30</strong> <em>(top image)</em>, then click <strong>Next: Add Tags</strong> in the bottom right <em>(bottom image)</em></p>

<p><img src="/doc_images/img34.jpg" alt="img34" width="60%" /></p>

<p><img src="/doc_images/img35.jpg" alt="img35" width="80%" /></p>

<p>9) On page <strong>Step 5: Add Tags</strong> - Click <strong>Add Tag</strong> on the left side of the screen <em>(top image)</em>. In the new row set the Key to be <strong>Name</strong> and the Value to be <code class="language-plaintext highlighter-rouge">&lt;username&gt;-cloud-workshop</code> just like we did with the S3 bucket earlier <em>(bottom image)</em>. Remember, <code class="language-plaintext highlighter-rouge">&lt;username&gt;</code> is the username you logged into the console with.</p>

<p><img src="/doc_images/img36.jpg" alt="img36" width="80%" /></p>

<p><img src="/doc_images/img37.jpg" alt="img37" width="80%" /></p>

<p>10) Click <strong>Next: Configure Security Group</strong> in the bottom right of the screen</p>

<p><img src="/doc_images/img38.jpg" alt="img38" width="80%" /></p>

<p>11) On page <strong>Step 6: Configure Security Group</strong> - Near the top of the screen, click <strong>Select an existing security group</strong>. Then click the box of the <strong>Default</strong> row at the top.</p>

<p><img src="/doc_images/img39.jpg" alt="img39" width="80%" /></p>

<blockquote>
  <p><strong>NOTE:</strong> This “default” network setting configuration leaves the instance open to public access. Typically you will want to restrict this to only trusted IP addresses, but for the purposes of the workshop we keep this open so there is no need to troubleshoot network issues. To balance this security flaw, we will restrict access to our instances with another instance feature in a few more steps.</p>
</blockquote>

<p>12) Click <strong>Review and Launch</strong> in the bottom right of the screen</p>

<p><img src="/doc_images/img40.jpg" alt="img40" width="60%" /></p>

<p>13) On page <strong>Step 7: Review and Launch</strong> – You should see two warnings at the top of the screen denoted by the symbol below. You can disregard these.</p>

<blockquote>
  <p><strong>NOTE:</strong> The first warning tells us that our instance configuration will cost us money. The second warning tells us that our network settings make our instance publicly accessible, which is discussed in the above “NOTE”.</p>
</blockquote>

<p><img src="/doc_images/img41.jpg" alt="img41" width="60%" /></p>

<p>14) Click <strong>Launch</strong> in the bottom right of the screen.</p>

<p><img src="/doc_images/img42.jpg" alt="img42" width="80%" /></p>

<p>15)	On the pop-up menu – change the first dropdown menu to <strong>Proceed without a key pair</strong> and check the box below it to acknowledge the change. Finally, click <strong>Launch Instances</strong> in the bottom right of the popup.</p>

<blockquote>
  <p><strong>NOTE:</strong> Key pairs are used to access this remote computer using other methods, like SSH. We won’t be using these other methods so we can skip the key pairs here without affecting our ability to do the workshop. Additionally, by disabling the key pairs we also prevent public access to the instance. (This is how we will secure our instances for the workshop)</p>
</blockquote>

<p><img src="/doc_images/img43.jpg" alt="img43" width="60%" /></p>

<p>16)	On the <strong>Launch Status</strong> page – Click <strong>View Instances</strong> in the bottom right</p>

<p><img src="/doc_images/img44.jpg" alt="img44" width="60%" /></p>

<p>17)	On the <strong>Instances</strong> page – Find your instance in the table of created instances and look to the <strong>Status Check</strong> column to see the status of yours.</p>

<p><img src="/doc_images/img45.jpg" alt="img45" /></p>

<p>18)	Refresh the page occasionally until the <strong>Status Check</strong> column changes to <strong>2/2 checks passed</strong> for your instance. This means we can now log into the instance.</p>

<blockquote>
  <p><strong>NOTE:</strong> There are several ‘statuses’ this column can have. 2/2 checks passed is the final status. So, if you see anything else in the <strong>Status Check</strong> column, the instance is not ready to go.</p>
</blockquote>

<p><img src="/doc_images/img46.jpg" alt="img46" /></p>

<p>19) Check the box to the left of your instance name <em>(top image)</em> to select the instance, then click <strong>Connect</strong> in the top right to head to the instance launcher <em>(bottom image)</em></p>

<p><img src="/doc_images/img47.jpg" alt="img47" width="70%" /></p>

<p><img src="/doc_images/img48.jpg" alt="img48" width="80%" /></p>

<p>20) On the launcher page, click <strong>Connect</strong> in the bottom right. This will launch a new tab in your browser and connect you to your remote computer!</p>

<p><img src="/doc_images/img49.jpg" alt="img49" width="60%" /></p>

<h2 id="installing-software">Installing Software</h2>

<p>Before we can do our analyses, we need to install some software into our new remote computer</p>

<p>1) First we need to update the pre-installed software in our terminal. Copy/paste the following command into your terminal, then hit <strong>Enter</strong></p>

<div class="code-header">
    <button class="copy-code-button" aria-label="Copy code to clipboard"></button>
</div>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">sudo </span>apt-get update
</code></pre></div></div>

<p>2) To download magicBLAST, copy/paste the following command into your terminal, then hit <strong>Enter</strong></p>

<div class="code-header">
    <button class="copy-code-button" aria-label="Copy code to clipboard"></button>
</div>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>curl <span class="nt">-o</span> magicblast.tar.gz https://ftp.ncbi.nlm.nih.gov/blast/executables/magicblast/LATEST/ncbi-magicblast-1.6.0-x64-linux.tar.gz
</code></pre></div></div>

<p>3) We also need to unpack the software so we can run it. Run the following command to do that</p>

<div class="code-header">
    <button class="copy-code-button" aria-label="Copy code to clipboard"></button>
</div>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">tar</span> <span class="nt">-xvzf</span> magicblast.tar.gz <span class="o">&amp;&amp;</span> <span class="nb">chmod</span> <span class="nt">-R</span> 755 ncbi-magicblast-1.6.0/
</code></pre></div></div>

<p>4) Next, we need to install samtools. Run the following command below to do that.</p>

<div class="code-header">
    <button class="copy-code-button" aria-label="Copy code to clipboard"></button>
</div>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">sudo </span>apt <span class="nb">install</span> <span class="nt">-y</span> samtools
</code></pre></div></div>

<p>5) Finally, we need to install the AWS command line interface. Run the following commands to do that</p>

<div class="code-header">
    <button class="copy-code-button" aria-label="Copy code to clipboard"></button>
</div>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">sudo </span>apt <span class="nb">install</span> <span class="nt">-y</span> unzip
</code></pre></div></div>

<div class="code-header">
    <button class="copy-code-button" aria-label="Copy code to clipboard"></button>
</div>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>curl <span class="nt">-o</span> awscliv2.zip https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip
</code></pre></div></div>

<div class="code-header">
    <button class="copy-code-button" aria-label="Copy code to clipboard"></button>
</div>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>unzip awscliv2.zip
</code></pre></div></div>

<div class="code-header">
    <button class="copy-code-button" aria-label="Copy code to clipboard"></button>
</div>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">sudo</span> ./aws/install
</code></pre></div></div>

<h2 id="mapping-reads-with-magicblast">Mapping Reads with MagicBLAST</h2>

<p>We can (finally) run MagicBLAST to align some reads! We just need two pieces of information to run the program.<br />
A.	The reference sequence – <em>Will be solved with Step 1 below</em><br />
B.	The accession numbers for our reads – <em>Will be solved with Step 2 below</em></p>

<p>1)	Based on the information from the manuscript, we know that the deleted region in the genome is on Chromosome 7. In NCBI, the accession number for this sequence is <strong>NC_000007</strong> so we can download this sequence to our remote computer and use it as the reference sequence for our alignment. Download the sequence using the following command.</p>

<div class="code-header">
    <button class="copy-code-button" aria-label="Copy code to clipboard"></button>
</div>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>curl <span class="nt">-o</span> chr7.fa <span class="s1">'https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=nuccore&amp;id=NC_000007&amp;rettype=fasta'</span>
</code></pre></div></div>

<p>2) Our Athena query gave us three different accession numbers that could be the child’s sequence data. To find out which one is associated with the child, scroll through the columns to find one that distinguishes each accession (<em>hint: it’s the library_name column</em>).</p>

<p><img src="/doc_images/img50.jpg" alt="img50" /></p>

<p>3) It looks like <strong>SRR6314034</strong> is the ID we want! To run MagicBLAST on our selected accession ID, run the following command. This should take ~1 minute to run. You’ll know it worked okay if the command runs with NO output.</p>

<div class="code-header">
    <button class="copy-code-button" aria-label="Copy code to clipboard"></button>
</div>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>./ncbi-magicblast-1.6.0/bin/magicblast <span class="nt">-subject</span> chr7.fa <span class="nt">-sra</span> SRR6314034 <span class="nt">-out</span> SRR6314034.sam
</code></pre></div></div>

<p>4) Next, we need to format the output files so that we can use them in Genome Data Viewer. Run the following samtools commands to do this. it will run each samtools command in order automatically. Like above, if NOTHING happened after hitting enter, then it worked!</p>

<div class="code-header">
    <button class="copy-code-button" aria-label="Copy code to clipboard"></button>
</div>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>samtools view <span class="nt">-S</span> <span class="nt">-b</span> SRR6314034.sam <span class="o">&gt;</span> SRR6314034.bam
</code></pre></div></div>

<div class="code-header">
    <button class="copy-code-button" aria-label="Copy code to clipboard"></button>
</div>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>samtools <span class="nb">sort </span>SRR6314034.bam <span class="nt">-o</span> SRR6314034.sorted.bam
</code></pre></div></div>

<div class="code-header">
    <button class="copy-code-button" aria-label="Copy code to clipboard"></button>
</div>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>samtools index SRR6314034.sorted.bam SRR6314034.sorted.bam.bai
</code></pre></div></div>

<p>5) Now we’ll move all these results files to a single folder so we can keep track of them</p>

<div class="code-header">
    <button class="copy-code-button" aria-label="Copy code to clipboard"></button>
</div>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">mkdir </span>results <span class="o">&amp;&amp;</span> <span class="nb">mv </span>SRR<span class="k">*</span> results/
</code></pre></div></div>

<p>6) Finally, we need to move these results files to our S3 bucket so we can access them outside of our AWS account. Run the following AWS CLI command to copy the files to your S3 bucket.</p>

<blockquote>
  <p><strong>REMEMBER:</strong> You will need to replace the <code class="language-plaintext highlighter-rouge">&lt;username&gt;</code> piece of the command with your own login username to make it match your S3 bucket name. So copy/paste the command into your terminal, then use the arrow keys to move your cursor back through the string and change the name to your own bucket.</p>
</blockquote>

<div class="code-header">
    <button class="copy-code-button" aria-label="Copy code to clipboard"></button>
</div>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>aws s3 <span class="nb">sync </span>results/ s3://&lt;username&gt;-cloud-workshop
</code></pre></div></div>

<p>7) To check if we got all of our files moved to our s3 bucket we can run one final command (remember to change the <code class="language-plaintext highlighter-rouge">&lt;username&gt;</code> portion again here):</p>

<div class="code-header">
    <button class="copy-code-button" aria-label="Copy code to clipboard"></button>
</div>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>aws s3 <span class="nb">ls </span>s3://&lt;username&gt;-cloud-workshop
</code></pre></div></div>

<p>8)	We should now be done with our remote computer (aka: EC2 instance). Go ahead and close the browser tab your instance is open in.</p>

<p><img src="/doc_images/img50B.jpg" alt="img50B" width="60%" /></p>

<p>9)	In the console webpage, click the blue <strong>Instances</strong> button at the top of the instance launcher page</p>

<p><img src="/doc_images/img51.jpg" alt="img51" width="60%" /></p>

<p>10) We don’t want to leave an instance on while not using it, because it costs money to keep it active. So, let’s shut it down, but not delete it, just in case we want to use it later. Check the box next to your instance <em>(top image)</em> then click the <strong>Instance State</strong> drop-down menu and select <strong>Stop Instance</strong> <em>(bottom image)</em>.</p>

<p><img src="/doc_images/img52.jpg" alt="img52" width="70%" /></p>

<p><img src="/doc_images/img53.jpg" alt="img53" width="60%" /></p>

<p>11) Finally, we need to check on the files in our S3 bucket and make them publicly available to upload the files to GDV later. Navigate back to the S3 page (use the search bar at the top of the console page) <em>(top image)</em> and click on your bucket name <em>(bottom image)</em> to see its contents</p>

<p><img src="/doc_images/img54.jpg" alt="img54" width="60%" /></p>

<p><img src="/doc_images/img55.jpg" alt="img55" width="60%" /></p>

<p>12) You should have four files in your bucket. We need the files that end in <strong>sorted.bam</strong> and <strong>sorted.bam.bai</strong>. Check the box next to each of those files <em>(top image)</em> then use the Actions drop-down menu and select <strong>Make Public</strong> at the very bottom <em>(bottom image)</em></p>

<p><img src="/doc_images/img56.jpg" alt="img56" width="60%" /></p>

<p><img src="/doc_images/img57.jpg" alt="img57" width="40%" /></p>

<p>13) On the new page, click the orange <strong>Make Public</strong> button in the bottom right of the page to make the files publicly accessible</p>

<p><img src="/doc_images/img59.jpg" alt="img59" width="60%" /></p>

<p>14) If it works, you will see a green banner at the top of the new page like seen below <em>(top image)</em>. If you see this, click your bucket link under the “summary” panel <em>(bottom image)</em> to navigate back to the main bucket page.</p>

<p><img src="/doc_images/img60.jpg" alt="img60" width="60%" /></p>

<p><img src="/doc_images/img62.jpg" alt="img62" width="60%" /></p>

<h1 id="objective-3---visualize-read-alignments-using-genome-data-viewer">Objective 3 - Visualize Read Alignments Using Genome Data Viewer</h1>

<h2 id="importing-our-data">Importing Our Data</h2>

<p>1)	Open a new tab in your web browser and go to <a href="https://ncbi.nlm.nih.gov/genome/gdv/">https://ncbi.nlm.nih.gov/genome/gdv/</a></p>

<p>2)	Make sure the <strong>Human</strong> is selected from the tree on the left</p>

<p><img src="/doc_images/img63.jpg" alt="img63" width="60%" /></p>

<p>3)	Scroll to the bottom of the page and click on the 7th Chromosome image to load the Genome Data Viewer on the human reference genome’s 7th chromosome</p>

<p><img src="/doc_images/img64.jpg" alt="img64" width="60%" /></p>

<p>4)	The GDV page comes pre-loaded with several tracks aligned against the chromosome. Most of these are not useful to us today, so we can use the red X buttons in the top right corner of each track to delete them. Do this for every track <strong>except the top one</strong>. This top track shows every gene and its position on the chromosome.</p>

<p><img src="/doc_images/img65.jpg" alt="img65" width="60%" /></p>

<blockquote>
  <p>There are LOTS of NCBI-offered tracks you can upload ato compare against your own data. To learn more about them click the little gear at the bottom of the viewer page:<br />
<img src="/doc_images/img66.jpg" alt="img66" /></p>
</blockquote>

<p>5) Now we can add our own tracks to the viewer. Click on <strong>User Data and Track Hubs</strong> on the left side of the screen</p>

<p><img src="/doc_images/img67.jpg" alt="img67" height="5%" width="60%" /></p>

<p>6) Click the <strong>Options</strong> pulldown menu and click <strong>Add Remote Files…</strong></p>

<p><img src="/doc_images/img68.jpg" alt="img68" width="60%" /></p>

<p>7)	Navigate back to your S3 bucket tab and click on the <strong>SRR6314034.sorted.bam</strong> file to open up the details for the file</p>

<p><img src="/doc_images/img70.jpg" alt="img70" width="=80%" /></p>

<p>8) On the new page, click the “Copy” button next to the <strong>Object URL</strong> to copy the URL path to the file to your clipboard</p>

<p><img src="/doc_images/img71.jpg" alt="img71" width="80%" /></p>

<p>9) Go back to your GDV tab and paste the link into the URL box. Next, add a familiar name like <code class="language-plaintext highlighter-rouge">Child</code> to the <strong>Name</strong> box to help us identify the track later. Then click <strong>Add</strong></p>

<p><img src="/doc_images/img72.jpg" alt="img72" width="60%" /></p>

<p>10) This track is showing all of the results of magicBLAST in a “pile-up” view. This is basically one long histogram plot where a taller bar represents a region of the chromosome where more reads from the sample aligned to. Because our sequences are specific to a single gene in the chromosome, but our current view is showing the entire chromosome, the pile-up view may look a little bland.<br />
Try to find the region of the chromosome that our reads aligned to:</p>

<p><img src="/doc_images/img73.jpg" alt="img73" /></p>

<p>11)	Use the scale bar at the top of the viewer and click-and-drag across the section where our reads aligned to highlight it. Then use the pop-up menu to click <strong>Zoom On Range</strong></p>

<p><img src="/doc_images/img74.jpg" alt="img74" height="50%" width="60%" /></p>

<p>12)	Repeat step 14 using the new view to refine the range again if the view didn’t change very much.</p>

<p><img src="/doc_images/img75.jpg" alt="img75" height="50%" width="60%" /></p>

<p>13)	Your view should now see the track similar to the screenshot below. If you don’t see the mess of red lines below the thick black bar, that’s okay! We will turn it off next anyway.</p>

<p><img src="/doc_images/img76.jpg" alt="img76" width="60%" /></p>

<blockquote>
  <p><strong>NOTE:</strong> The tracks may be slightly different depending on how you have zoomed in. As long as you can see the image above somewhere on your screen you are doing great!</p>
</blockquote>

<p>14) Those red lines underneath the thick black box are showing how each individual sequence read aligned to the reference sequence. This particular view isn’t very helpful to us, so let’s turn it off.</p>

<blockquote>
  <p><strong>NOTE:</strong> If you can’t see these lines, that’s great! You can skip Steps 15 &amp; 16</p>
</blockquote>

<p>15) Click the little gear in the top right corner of our Child track to open its settings.</p>

<p><img src="/doc_images/img77.jpg" alt="img77" /></p>

<p>16)	On this new menu page, change the “Alignment Display” to “Packed” and then click <strong>Accept</strong>. You can change many other settings here as well, but I’ll leave that up to you to explore outside of this workshop.</p>

<p><img src="/doc_images/img78.jpg" alt="img78" width="60%" /></p>

<p>Now that we can see the range a bit better, let’s break down what each of these colors represent in the pile-up view:</p>

<ul>
  <li><strong>Grey</strong> – This is the standard “bar” for the pile-up view. The taller this bar is in a particular region, the greater the coverage is from the mapped reads.</li>
  <li><strong>Red</strong> – These are locations in the genome where reads mapped, but with mismatches in the nucleotide sequence compared to the reference sequence.</li>
  <li><strong>Black</strong> – These are gaps that exist in the read alignment to the reference genome (i.e., the reads only have a nucleotide sequence that covers before/after the large black chunk).</li>
</ul>

<p>If you want to explore the pile-up view a bit more, try using the buttons in the toolbar just above the numeric range to navigate the assembly. Hold your mouse over the button for a description of what they can do!</p>

<h2 id="adding-ncbi-data">Adding NCBI Data</h2>

<p>1)	Click the <strong>Tracks</strong> button in the bottom right corner of the viewer panel to open the Configure Page</p>

<p><img src="/doc_images/img79.jpg" alt="img79" /></p>

<p>2) Click on the <strong>Variation</strong> tab and scroll way WAY down to the <strong>dbVar</strong> category. Then click the checkbox next to <strong>dbVar Pathogenic Clinical Structural Variants</strong> then click <strong>Configure</strong> in the bottom right corner of the page.</p>

<p><img src="/doc_images/img80.jpg" alt="img80" width="60%" /></p>

<p>3) You should now have a new structural variants track loaded into the viewer. This track shows the region of the genome where each variant is found. Blue variants are caused by an insertion in this region, while Red variants are caused by a deletion. Because our alignment suggests a deletion, we want to focus on the red variants.</p>

<p><img src="/doc_images/img81.jpg" alt="img81" height="70%" width="60%" /></p>

<p>4) Next, zoom in on the right-half of our aligned region in the child track like the screenshot below. We want to look closely at the BBS9 gene to find structural variants that overlap with this region.</p>

<p><img src="/doc_images/img82.jpg" alt="img82" width="60%" /></p>

<p>5)	Obviously, there are a LOT of variants that overlap in this region. However, our concern is only about our sequenced region of the gene. Variants which extend beyond our sequenced region are less likely to be relevant for us. So rather than just aimlessly checking every red variant, lets look only for variants that start or stop within our deletion.</p>

<p>Oh… there’s just one? Let’s check that one then.</p>

<p><img src="/doc_images/img83.jpg" alt="img83" width="60%" /></p>

<p>6)	Mouse over the variant <strong>nsv1398255</strong> to get a new pop-up menu and select the dbVar link at the bottom of it</p>

<p><img src="/doc_images/img84.jpg" alt="img84" width="60%" /></p>

<p>7) On the dbVar page, navigate to the <strong>Clinical Assertions</strong> panel to see which clinical conditions have been associated with this deletion</p>

<p><img src="/doc_images/img85.jpg" alt="img85" /></p>

<p>8) Just as we suspected! This region is associated with Bardet-biedl syndrome. If we wanted to, we could click on the phenotype and explore more about the condition. But that is something you need to explore on your own, because this is the end of the worksheet!</p>

<h1 id="conclusion">Conclusion</h1>

<p>This concludes our exercise on navigating the AWS Cloud computing console and several of its most popular cloud services. We hope that you are motivated to take these skills and tools with you and explore how they can benefit your own research. You can find links to many useful resources to help you below.</p>

<h1 id="useful-urls">Useful URLs</h1>

<ul>
  <li>Case Study - <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5778042/">https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5778042/</a></li>
</ul>

<p><strong>AWS</strong></p>

<ul>
  <li>AWS Account Creation: <a href="https://aws.amazon.com/premiumsupport/knowledge-center/create-and-activate-aws-account/">https://aws.amazon.com/premiumsupport/knowledge-center/create-and-activate-aws-account/</a></li>
  <li>AWS Athena Documentation: <a href="https://docs.aws.amazon.com/athena/">https://docs.aws.amazon.com/athena/</a></li>
  <li>AWS Billing: <a href="https://docs.aws.amazon.com/awsaccountbilling/latest/aboutv2/billing-what-is.html">https://docs.aws.amazon.com/awsaccountbilling/latest/aboutv2/billing-what-is.html</a></li>
  <li>Cost Estimator: <a href="https://calculator.aws/#/estimate">https://calculator.aws/#/estimate</a></li>
  <li>AWS CLI Documentation: <a href="https://docs.aws.amazon.com/cli/index.html">https://docs.aws.amazon.com/cli/index.html</a></li>
  <li>AWS EC2 Instance Documentation: <a href="https://docs.aws.amazon.com/ec2/index.html">https://docs.aws.amazon.com/ec2/index.html</a></li>
  <li>AWS Glue Documentation: <a href="https://docs.aws.amazon.com/glue/">https://docs.aws.amazon.com/glue/</a></li>
  <li>AWS S3 Bucket Documentation: <a href="https://docs.aws.amazon.com/s3/index.html">https://docs.aws.amazon.com/s3/index.html</a></li>
</ul>

<p><strong>Genome Data Viewer</strong></p>

<ul>
  <li>Genome Data Viewer: <a href="https://www.ncbi.nlm.nih.gov/genome/gdv/">https://www.ncbi.nlm.nih.gov/genome/gdv/</a></li>
  <li>Sequence Viewer Documentation: <a href="https://www.ncbi.nlm.nih.gov/tools/sviewer/">https://www.ncbi.nlm.nih.gov/tools/sviewer/</a></li>
</ul>

<p><strong>MagicBLAST</strong></p>

<ul>
  <li>MagicBLAST Documentation: <a href="https://ncbi.github.io/magicblast/">https://ncbi.github.io/magicblast/</a></li>
  <li>MagicBLAST FTP page: <a href="ftp://ftp.ncbi.nlm.nih.gov/blast/executables/magicblast/LATEST">ftp://ftp.ncbi.nlm.nih.gov/blast/executables/magicblast/LATEST</a></li>
  <li>SamTools Documentation: <a href="http://www.htslib.org/">http://www.htslib.org/</a></li>
</ul>

<p><strong>SRA</strong></p>

<ul>
  <li>SRA Homepage: <a href="https://www.ncbi.nlm.nih.gov/sra">https://www.ncbi.nlm.nih.gov/sra</a></li>
  <li>SRA in the Cloud: <a href="https://www.ncbi.nlm.nih.gov/sra/docs/sra-cloud/">https://www.ncbi.nlm.nih.gov/sra/docs/sra-cloud/</a></li>
</ul>

<h1 id="supplementary-information">Supplementary Information</h1>

<h2 id="instructions-for-aws-glue">Instructions for AWS Glue</h2>

<p>In order search through a table (like the SRA metadata table) you need to load it into Athena. Because this is your first-time accessing Athena, it shouldn’t be a surprise that you don’t currently have any data tables loaded! Therefore, our first step will be to add the SRA metadata table to Athena. There are three ways you can add a table to Athena:</p>

<ol>
  <li>
    <p>Create the table using SQL commands (we are not SQL experts here…yet, so we won’t do it this way)</p>
  </li>
  <li>
    <p>Add the table manually from an S3 bucket (although the SRA metadata is stored in its own S3 bucket, we don’t know the format of the table, so we can’t do it this way)</p>
  </li>
  <li>
    <p><strong>Use another AWS service called AWS Glue to automatically parse a table and load it into Athena for us using a “Crawler” (this is what we will do)</strong></p>
  </li>
</ol>

<blockquote>
  <p><strong>Note:</strong> Although AWS Glue is the most convenient method, it is also the only one to cost money. To parse the SRA metadata table it will be… ~$0.01.</p>
</blockquote>

<p>This section will walk through the steps taken during the AWS Glue demo to prepare the SRA metadata table for Athena queries</p>

<p>1) To start working with AWS Glue, navigate to the <strong>Tables</strong> section of the Athena page on the left-hand side, then click <strong>Create Table</strong> and select <strong>from AWS Glue Crawler</strong> as seen below. If you see a pop-up about the crawler, just click <strong>Continue</strong>.</p>

<p><img src="/doc_images/img86.jpg" alt="img86" width="60%" /></p>

<p>2) The settings for this crawler should e set as described below:</p>

<ul>
  <li>Crawler name: This name needs to be informative, but not universally unique (like an S3 bucket). Choose something that helps you remember what the crawler is trying to access.</li>
</ul>

<p><strong>Next page</strong></p>

<ul>
  <li>Crawler Source Type: Keep the default setting (<strong>data stores</strong>)</li>
  <li>Repeat crawls of S3 data stores: Keep the default setting (<strong>Crawl all folders</strong>)</li>
</ul>

<p><strong>Next page</strong></p>

<ul>
  <li>Choose a data store: Set it to <strong>S3</strong></li>
  <li>Connection: Leave empty</li>
  <li>Crawl data in: Select <strong>Specified path in another account</strong></li>
  <li>Include path: This is the path to the table itself. The SRA metadata table used here is located at <strong>s3://sra-pub-metadata-us-east-1/sra/metadata/</strong></li>
</ul>

<p><strong>Next page</strong></p>

<ul>
  <li>Add another data store: Select <strong>No</strong>. However, crawlers <em>can</em> parse multiple tables at a time, so you can add this if you want.</li>
</ul>

<p><strong>Next page</strong></p>

<ul>
  <li>Choose an IAM role: Work with your admin to determine the correct choice for you. If you are doing this on your own, I recommend creating your own IAM role and reusing it if you need additional crawlers.</li>
</ul>

<p><strong>Next page</strong></p>

<ul>
  <li>Frequency: Select <strong>Run on Demand</strong>. Crawlers can be run on specified intervals, but this costs extra money, and for most purposes is unecessary.</li>
</ul>

<p><strong>Next page</strong></p>

<ul>
  <li>Database: Select <strong>Add database</strong> then make a name for it. The tables parsed by this crawler will be stored in this database. Then click <strong>Create</strong>.</li>
  <li>Prefix added to tables (optional) - Leave empty.</li>
</ul>

<p><strong>Next Page</strong></p>

<p><strong>Click Finish</strong></p>

<p>3) You should now be on the <strong>Crawler</strong> page for AWS Glue. Here you can manage and run crawlers. Click the checkbox next to the new crawler and select <strong>Run Crawler</strong></p>

<p><img src="/doc_images/img87.jpg" alt="img87" width="80%" /></p>

<p>4) If it worked, you should see the <strong>Status</strong> column say <strong>Ready</strong> again, and the <strong>Tables added</strong> column should have changed to 1:</p>

<p><img src="/doc_images/img88.jpg" alt="img88" width="80%" /></p>

<p>5) The table should now appear in Athena and you can follow the same steps described in section <strong>Exploring Athena Tables</strong> above.</p>

<h2 id="sql-challenges">SQL Challenges</h2>

<p>Now that you have a handle on how SQL commands work, let’s try some examples! Remember, you can use the “Tables” section on the left-hand side of the page to find out which columns you can filter by in your table.</p>

<p>If you find yourself stumped on the answer to any of these, or just want to check your answer, click the dropdown box underneath the question to reveal the solution and see a screenshot of the results table!</p>

<p>a) You just came across a new paper with lots of great sequence data. You want to add that data to your own research so you jump to the paper’s Data Availability section (because all great computational papers have one!) and see that the data was stored in an SRA study under the accession SRP291000. Write a SQL command in the query terminal to find all data associated with the SRA study accession SRP291000:</p>

<details>
  <summary><strong>Click here to see solution!</strong></summary>
  <p><code class="language-plaintext highlighter-rouge">SELECT * FROM "sra"."metadata" WHERE sra_study = 'SRP291000'</code>
<img src="/doc_images/img89.jpg" alt="img89" /></p>
</details>
<p><br />
</p>

<p>b) You are working on a new genome assembly tool for short-read sequences. However, you don’t have any reads of your own to test it! You know that SRA metadata includes the sequencing platform reads were generated on, so you decide you want to check there. Write a SQL command in the query terminal to find all data sequenced with the OXFORD_NANOPORE platform.</p>

<details>
  <summary><strong>Click here to see solution!</strong></summary>
  <p><code class="language-plaintext highlighter-rouge">SELECT * FROM "sra"."metadata" WHERE platform = 'OXFORD_NANOPORE'</code>
<img src="/doc_images/img90.jpg" alt="img90" /></p>
</details>
<p><br />
</p>

<p>Now let’s get a little bit more complicated with our queries by combining multiple filtering conditions together. For example, see the command below:</p>

<p><img src="/doc_images/img91.jpg" alt="img91" width="80%" /></p>

<p>In this command we use the <strong>AND</strong> statement to add multiple requirements for our data. Specifically, we added a second criteria where the <em>consent = public</em> (aka: The data is not under restricted access). Additionally, we add a more complex requirement by using an <strong>OR</strong> statement for the <em>platform</em> column to ask for data that was generated by the <em>OXFORD_NANOPORE OR PACBIO_SMRT</em> sequencing platforms. Overall, by running this command we will only get the data that fits all 3 conditions.</p>

<blockquote>
  <p><strong>Note:</strong> Make sure you include parenthesis around an OR statement as seen above, otherwise the query may not work as intended.</p>
</blockquote>

<p>Here’s a few brain teasers to flex your new SQL skills! Remember, if you are stuck you can click the dropdown box underneath the question to reveal the solution and see a screenshot of the results table!</p>

<p>a)	After testing your genome assembly tool from earlier, you realize that not all Illumina datasets are created equally! It turns out you only need WGS (Whole Genome Sequencing) genomic data to properly validate your software. Also, you noticed that there was some metagenomic and transcriptomic data mixed in with your test cases. So, this time you are just going to look for “genomic” datasets. Write a SQL command in the query terminal to find all <strong>WGS assay_type</strong> data sequenced on the <strong>ILLUMINA platform</strong> and a <strong>GENOMIC library_source</strong>.</p>

<details>
  <summary><strong>Click here to see solution!</strong></summary>
  <p><code class="language-plaintext highlighter-rouge">SELECT * FROM "sra"."metadata" WHERE platform = 'ILLUMINA' AND assay_type = 'WGS' AND librarysource = 'GENOMIC'</code>
<img src="/doc_images/img92.jpg" alt="img92" /></p>
</details>
<p><br />
</p>

<p>b) You are designing a population-level epidemiological survey of some bacterial pathogens from samples collected across Europe. You decide you want to get some preliminary data on <em>Escherichia coli</em> (or maybe <em>Staphylococcus aureus</em>…) from the SRA, but you aren’t picky about what kind of sequencing is done just yet. Write a SQL command in the query terminal to find all sequences collected from the <strong>continent Europe</strong> and are from the <strong>organism Escherichia coli or Staphylococcus aureus</strong>.</p>

<p><em>Hint: The column header for the continent is not very intuitive. Try using the “Preview Table” option from the “Tables” tab described earlier to find a column that would fit.</em></p>

<details>
  <summary><strong>Click here to see solution!</strong></summary>
  <p><code class="language-plaintext highlighter-rouge">SELECT * FROM "sra"."metadata" WHERE (organism = 'Escherichia coli' OR organism = 'Staphylococcus aureus') AND geo_loc_name_country_continent_calc = 'Europe'</code>
<img src="/doc_images/img93.jpg" alt="img93" /></p>
</details>
<p><br />
</p>


      </section>
      <footer>
      <!--  <img src="doc_images/NCBI_screenshot.jpg" alt="NCBI" width="150" height="30"> -->
      </footer>
    </div>

    
    <script src="/assets/scripts/copyCode.js"></script>
  </body>
</html>
